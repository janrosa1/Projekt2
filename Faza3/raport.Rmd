---
title: "Modele predykcji zachorowań na raka"
author: "Patrzycja Matys, Jan Rosa, Krzysztof Rutkowski, Magda Sobiczewska"
date: "18 czerwca 2016"
output: html_document
---

#Wprowadzenie
#Metodologia i wybór czynników
#Użyte modele
##Modele liniowe
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(knitr)
mse <- function(pred, y) {
  return(mean((pred-y)^2, na.rm=TRUE))
}
rmse <- function(pred, y) {
  return(sqrt(mean((pred-y)^2, na.rm=TRUE)))
}
```
Z modeli linowych na początku oszacowano zwykły model regresji. W zbiorze zmeinnych objaśnianych znalazły się wszytskie rozważane przez nas zmienne, czyli: 
<ul>
<li>wiek</li>
<li>płeć</li> 
<li>stężenie szkodliwych pyłów</li> 
<li>spożycie alkoholu alkoholu wśród kobiet</li> 
<li>spożycie alkoholu alkoholu wśród mężczyzn</li> 
<li>otyłość</li> 
<li>urbanizację</li> 
<li>gęstość zaludnienia</li>
<li>liczbę osób zarejestrowanych w poradniach psychologicznych</li> 
<li>liczbę osób z zabrzeniami psychicznymi</li>
<li>liczbę osób chorych w poprzednim okresie</li>
</ul> 
Dodano także interakcje miedzy zmiennymi wiek a urbanizacja. Otrzymano następujące modele.

```{r cars, echo=FALSE}
#print(getwd())
load(file="regresja_dane.Rdata")
fit1_normal1<-lm(zm_dec.x~ GAZY +GESTOSC+ZIELONE+ URBANIZACJA+
                   ZAGROZENIA+PYLY+GENDER*Fotytly*URBANIZACJA+
                   GENDER*Falkohol*URBANIZACJA+GENDER*Motytly+GENDER*Malkohol+
                   URBANIZACJA+as.factor(AGE_GROUP)*URBANIZACJA+nsrednia.y+zsrednia.y+nsrednia.y*URBANIZACJA+opoznienie, data=y11)

fit1_aic<-step(fit1_normal1,data=grupa_m3, direction="backward",criterion = "BIC", trace=0)
```

Model wybrany na podstawie kryterium BIC radzi sobie nieco lepiej od modelu wykorzystujacego wszytskie zmienne.

```{r kable, echo=FALSE}
res <- data.frame(matrix(ncol=2, nrow=2))
colnames(res) <- c("model", "wyniki")
res$model <- c("normal", "aic")
res$wyniki <- c(rmse(predict(fit1_normal1,y12), y12$zm_dec.x)*10^5, 
                rmse(predict(fit1_aic,y12), y12$zm_dec.x)*10^5)
kable(res)
```

Następnie na oszacowano uogólnione modele regresji  wykorzystujące wszytskie zmienne.
Z współczynnik alfa przyjęto:
<ul>
<li>1.0 (lasso)</li>
<li>0.5</li> 
<li>0.25</li> 
<li>0.0 (ridge)</li> 
</ul>
```{r, echo=FALSE}
f <- as.formula(zm_dec.x~ GAZY +GESTOSC+ZIELONE+ URBANIZACJA+
                  ZAGROZENIA+PYLY+Fotytly*URBANIZACJA+
                  Falkohol+Motytly+GENDER*Malkohol+
                  URBANIZACJA+as.factor(AGE_GROUP)+nsrednia.y+zsrednia.y
                +nsrednia.y*URBANIZACJA+opoznienie)
                
options(na.action='na.omit')

x1 <- model.matrix(f, y11,na.action=NULL)
x2<-as.data.frame(x1)
y1 <- na.omit(y11)
library(glmnet)

wynik_cv_lasso<-cv.glmnet(x=x1,y=as.matrix(y1[,17]), alpha=1)
wynik_cv_ridge<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=0)
wynik_cv_pol<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/2)
wynik_cv_pol1<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/4)


y12<-subset(y12, TERYT4!=1461)
y2 <- na.omit(y12)
y21 <- y12[complete.cases(y12),]

wynik_cv_lasso_pred<-predict.cv.glmnet(object =wynik_cv_lasso,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_ridge_pred<-predict.cv.glmnet(object =wynik_cv_ridge,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_pol_pred<-predict.cv.glmnet(object =wynik_cv_pol,newx=model.matrix(f, y12,na.action=NULL),)
wynik_cv_pol1_pred<-predict.cv.glmnet(object =wynik_cv_pol1,newx=model.matrix(f, y12,na.action=NULL),)


```
Wyniki dla uogólnionych modeli
```{r, echo=FALSE}
res <- data.frame(matrix(ncol=2, nrow=4))
colnames(res) <- c("model", "wyniki")
res$model <- c("lasso", "ridge", "alfa 0.5", "alfa 0.25")
res$wyniki <- c(rmse(y2[,17], wynik_cv_lasso_pred)*10^5, 
                rmse(y2[,17], wynik_cv_ridge_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol1_pred)*10^5)
kable(res)
```

Następnie przeanalizowano modele glm dla tego samego zestawu zmienneych jak w modelu linowym wybranym na podtswie krytrium BIC. Analogicznie przetestowano ich moc predykcyjną.

```{r, echo=FALSE}
f1<-formula(fit1_aic)

x1 <- model.matrix(f1, y11,na.action=NULL)
y1 <- na.omit(y11)


wynik_cv_lasso<-cv.glmnet(x=x1,y=as.matrix(y1[,17]), alpha=1)
wynik_cv_ridge<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=0)
wynik_cv_pol<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/2)
wynik_cv_pol1<-cv.glmnet(x=x1,y=as.matrix(y1[,17]),alpha=1/4)



y2 <- na.omit(y12)

wynik_cv_lasso_pred<-predict.cv.glmnet(object =wynik_cv_lasso,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_ridge_pred<-predict.cv.glmnet(object =wynik_cv_ridge,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_pol_pred<-predict.cv.glmnet(object =wynik_cv_pol,newx=model.matrix(f1, y12,na.action=NULL),)
wynik_cv_pol1_pred<-predict.cv.glmnet(object =wynik_cv_pol1,newx=model.matrix(f1, y12,na.action=NULL),)


res <- data.frame(matrix(ncol=2, nrow=4))
colnames(res) <- c("model", "wyniki")
res$model <- c("lasso", "ridge", "alfa 0.5", "alfa 0.25")
res$wyniki <- c(rmse(y2[,17], wynik_cv_lasso_pred)*10^5, 
                rmse(y2[,17], wynik_cv_ridge_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol_pred)*10^5,
                rmse(y2[,17], wynik_cv_pol1_pred)*10^5)
kable(res)
```

Ostaecznie więc przetestowanie mocy predykcyjnej modeli na danych z 2012 roku wskazało iz najlepiej radzi sobie model liniowy, z zestawiem zmiennych wybranych na podtsawie kryterium BIC.  

Przeprowadzono takz analizy dla modeli estymowyanych osobno dla obu płci, jednak ich moc predykcyjna okazała sie zdecydowanie gorsza.

##Pozostałe modele
#Końcowy model
#Wnioski

